# ============================================================================
# CONTAINER IMAGE CONFIGURATION
# ============================================================================
# IMAGE_TAG: Controls which version of orchestrator/worker images to pull from GHCR
#
# PRODUCTION (REQUIRED): Pin to a release tag or commit SHA for reproducibility
#   Examples:
#     IMAGE_TAG=v1.2.3        # Semantic version tag
#     IMAGE_TAG=abc1234       # Short commit SHA from GitHub
#     IMAGE_TAG=sha-abc1234   # Explicit SHA prefix
#
# DEV/TESTING ONLY: Use 'main' to track the latest build
#   IMAGE_TAG=main          # NOT RECOMMENDED for production
#
# Default if unset: 'main' (see compose files)
#
# Production workflow:
#   1. export IMAGE_TAG=abc1234
#   2. docker compose pull
#   3. docker compose up -d
#   4. docker compose images  # Verify correct tags are running
#
# IMAGE_TAG=

# Database
POSTGRES_USER=researchflow
POSTGRES_PASSWORD=dev_password
POSTGRES_DB=researchflow_dev
DATABASE_URL=postgresql://researchflow:dev_password@postgres:5432/researchflow_dev

# Services
# NOTE: Use docker network names (orchestrator:3001, worker:8000) for inter-service
# communication. Use public URLs (https://your-domain.com) only if services are exposed externally.
WORKER_CALLBACK_URL=http://worker:8000
ORCHESTRATOR_URL=http://orchestrator:3001

# AI Providers (use test/mock values in CI)
OPENAI_API_KEY=sk-test-placeholder
ANTHROPIC_API_KEY=sk-ant-test-placeholder
XAI_API_KEY=test-placeholder
MERCURY_API_KEY=
INCEPTION_API_KEY=
INCEPTIONLABS_API_KEY=
# MERCURY_CHAT_MODEL=mercury
# MERCURY_CODER_MODEL=mercury-coder-small
# MERCURY_ENABLED=true
# AI_TIER_PROVIDER_NANO=mercury
# AI_TIER_PROVIDER_MINI=mercury
# AI_TIER_PROVIDER_FRONTIER=mercury
# AI_TIER_MODEL_NANO=mercury

# Optional integrations (can be blank)
EXA_API_KEY=
FIGMA_API_KEY=
NCBI_API_KEY=
SEMANTIC_SCHOLAR_API_KEY=
STRIPE_WEBHOOK_SECRET=
ZOOM_WEBHOOK_SECRET_TOKEN=
ZOOM_VERIFICATION_TOKEN=
NOTION_API_KEY=
SOURCEGRAPH_API_KEY=

# ----------------------------------------
# Mercury Coder / Inception Labs Integration
# Ultra-fast diffusion LLM for code completion
# ----------------------------------------
MERCURY_BASE_URL=https://api.inceptionlabs.ai/v1
MERCURY_MODEL=mercury-coder-small
MERCURY_REALTIME_ENABLED=true
# Auto-routing: When enabled, Mercury is used for low-latency tasks
MERCURY_AUTO_ROUTE=true
# Realtime mode for near-instant responses
MERCURY_REALTIME_MODE=true
# Structured outputs for JSON schema enforcement
MERCURY_STRUCTURED_OUTPUTS=true

# App settings
NODE_ENV=test
LOG_LEVEL=info

# Governance Mode (DEMO, STANDBY, LIVE)
# LIVE mode enables full AI-assisted workflow execution with real data
GOVERNANCE_MODE=LIVE

# ============================================
# Artifact Storage (Worker)
# ============================================
# Primary artifact storage path - survives container restarts via volume mount
# Mounted to shared-data volume in docker-compose.yml
ARTIFACTS_PATH=/data/artifacts
# Legacy alias (deprecated, use ARTIFACTS_PATH)
# ARTIFACT_PATH=/data/artifacts
